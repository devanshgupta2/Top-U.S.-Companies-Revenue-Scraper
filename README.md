# Top-U.S.-Companies-Revenue-Scraper

## Overview

The Top U.S. Companies Revenue Scraper is a Python-based project designed to scrape data from Wikipedia about the largest companies in the United States by revenue. This project uses the Pandas library for data manipulation and analysis. The primary goal of this scraper is to extract and organize information on these companies for further analysis or reporting.

## Features

- Scrapes the list of largest U.S. companies by revenue from Wikipedia.
- Utilizes Python and the Pandas library for data extraction and manipulation.
- Outputs a clean, organized dataset in CSV format.

## Requirements

- Python 3.x
- Pandas
- Requests (for making HTTP requests)
- BeautifulSoup4 (for parsing HTML)

## Steps in the Project

- Data Extraction
- Data Parsing
- Data Cleaning and Structuring

## Example

After running the script, the top_us_companies_revenue.csv file will contain columns such as:

- Company Name
- Revenue
- Industry
- Country
- Headquarters

## Results and Insights

The resulting DataFrame provided a clear overview of the top U.S. companies by revenue, allowing for easy identification of leading corporations and their financial standings. The analysis revealed key players in various industries and offered insights into revenue distribution among the largest companies.

## Conclusion
This web scraping project, utilizing Python and Pandas, demonstrated the power and efficiency of these tools for data extraction and analysis. By scraping the Wikipedia page for the largest U.S. companies by revenue, I was able to compile and analyze a valuable dataset, showcasing the practical applications of web scraping in data science.

This project not only reinforced my skills in Python programming and data manipulation but also provided a deeper understanding of the economic landscape of major U.S. corporations.

## Notes

- Ensure you comply with Wikipedia's terms of service when scraping data.
- The project assumes Wikipedia's page structure remains consistent; changes to the page structure may require updates to the scraping logic

